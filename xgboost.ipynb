{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook fits the baseline model. It predicts on the test data without doing any feature engineering, using the xgboost library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast discrete columns to the \"category\" dtype for the xgboost library. It can handle category dtypes without a numeric encoding.\n",
    "# list of discrete columns\n",
    "cats = data.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "for col in data:\n",
    "   data[col] = data[col].astype('category')\n",
    "\n",
    "# create features and target arrays\n",
    "X, y = data.drop('Status', axis=1), data[['Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the target needs to be numerical for multiclass classification\n",
    "# create a recode mapping\n",
    "mapping = {'C': 1, 'CL': 2, 'D': 3}\n",
    "y = y.replace(mapping).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/test split on the data\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression matrices in xboost's data format\n",
    "dtrain = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_dev, y_dev, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "params = {\n",
    "    # objective for multiclass classification.\n",
    "    # for regression it would be reg:squarederror, for example.\n",
    "    \"objective\": \"multi:softprob\", \n",
    "    \"tree_method\": \"hist\"} # optimization without a GPU\n",
    "\n",
    "# specify the names of the data for xgboost to use\n",
    "evals = [(dtrain, \"train\"), (dtest, \"validation\")]\n",
    "n = 100\n",
    "\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain,\n",
    "   num_boost_round=n,\n",
    "   evals=evals,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
