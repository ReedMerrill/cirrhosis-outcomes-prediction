{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook fits the baseline model. It predicts on the test data without doing any feature engineering, using the xgboost library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv').drop(['id'], axis=1)\n",
    "df_train['source'] = 'simulation'\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "test_ids = df_test.id\n",
    "dt_test = df_test.drop(['id'], axis=1)\n",
    "\n",
    "df_supp = pd.read_csv('data/cirrhosis.csv').drop(['ID'], axis=1)\n",
    "df_supp['source'] = 'original'\n",
    "\n",
    "# merge supplemental data\n",
    "df_train = pd.concat([df_train, df_supp]).reset_index(drop=True)\n",
    "train_target = df_train['Status']\n",
    "\n",
    "TARGET = 'Status'\n",
    "SKEWED_FEATS = ['Bilirubin', 'Cholesterol', 'Copper', 'Prothrombin', 'Alk_Phos']\n",
    "CAT_FEATS = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Stage']\n",
    "NUM_FEATS = [x for x in df_train.columns if x not in CAT_FEATS and x != TARGET]\n",
    "NUM_FEATS.remove('source')\n",
    "ORIG_FEATS = df_train.drop(TARGET, axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data for XGBoost\n",
    "\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transformation(data, skewed_features):\n",
    "    df_log_feats = pd.DataFrame()\n",
    "    for col in skewed_features:\n",
    "        name = f'{col}_log'\n",
    "        df_log_feats[name] = np.log(data[col])\n",
    "    return df_log_feats\n",
    "\n",
    "def encode(data):\n",
    "    X_raw = data.iloc[:, 0:18]\n",
    "\n",
    "    # encode the categorical features\n",
    "    X_cat = X_raw[CAT_FEATS]\n",
    "    X_num = np.array(X_raw[NUM_FEATS])\n",
    "    oe = OrdinalEncoder()\n",
    "    X_cat = oe.fit_transform(X_cat)\n",
    "    X_cat = pd.DataFrame(X_cat, columns=CAT_FEATS)\n",
    "    X_num = pd.DataFrame(X_num, columns=NUM_FEATS)\n",
    "    return X_cat, X_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and target arrays\n",
    "X, y = df_train.drop(TARGET, axis=1), df_train[[TARGET]]\n",
    "\n",
    "# encode features\n",
    "X_cat, X_num = encode(X)\n",
    "X = pd.concat([X_cat, X_num], axis=1)\n",
    "\n",
    "# encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(np.ravel(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n symptoms\n",
    "# recode edema \"S\" and \"Y\" to both indicate edema for the purpose of this count variable\n",
    "X['Edema'] = np.where(X['Edema'] == 2, 1, X['Edema'])\n",
    "X['N_Symptoms'] = X.Edema + X.Spiders + X.Ascites + X.Hepatomegaly\n",
    "\n",
    "# logarithmic transformations\n",
    "def get_logs(data, skewed_features):\n",
    "    X_log = X[skewed_features]\n",
    "    other_feats = data.columns.difference(skewed_features).tolist()\n",
    "    X_other = X[other_feats]\n",
    "    X_log = log_transformation(X_log, skewed_features)\n",
    "    return pd.concat([X_log, X_other], axis=1)\n",
    "\n",
    "X = get_logs(X, SKEWED_FEATS)\n",
    "\n",
    "# Age at Diagnosis\n",
    "X['Dgns_Age'] = X['Age'] - X['N_Days']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/test split on the data\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model\n",
    "\n",
    "## Define wandb sweep parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"random\", # sweep method\n",
    "    \"metric\": {\n",
    "        \"name\": \"accuracy\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"booster\": { # tree-based or linear functions?\n",
    "            \"value\": 'gbtree'\n",
    "        },\n",
    "        \"max_depth\": { # depth of individual trees\n",
    "            \"values\": [5, 6, 7]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            'distribution': 'uniform',\n",
    "            'min': .04,\n",
    "            'max': .09,\n",
    "        },\n",
    "        \"subsample\": { # the proportion of instances to take as a sub-sample per iteration\n",
    "            'distribution': 'uniform',\n",
    "            'min': .33,\n",
    "            'max': 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='cirrhosis-xgb-sweeps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training function\n",
    "def train():\n",
    "    config_defaults = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"max_depth\": 3,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"subsample\": 1,\n",
    "        \"seed\": 1,\n",
    "    }\n",
    "\n",
    "    wandb.init(config=config_defaults) # set defaults. They'll be over-ridden later.\n",
    "    config = wandb.config\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=10_000,\n",
    "        early_stopping_rounds=2,\n",
    "        learning_rate=config.learning_rate,\n",
    "        booster=config.booster,\n",
    "        max_depth=config.max_depth,\n",
    "        subsample=config.subsample\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_dev, y_dev)])\n",
    "\n",
    "    # get predictions on dev set\n",
    "    y_pred = model.predict(X_dev)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_dev, predictions)\n",
    "    print(f\"Accuracy: {accuracy:.0%}\")\n",
    "    wandb.log({\"accuracy\": accuracy})\n",
    "\n",
    "    #model.save_model(f'checkpoints/{config.booster}\"-\"{config.max_depth}\"-\"{config.learning_rate}\"-\"{config.subsample}\"-\"{time.time()}.json') \n",
    "    # with a categorical target, if its not json then it throws an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "# specify the sweep, the training function, and the number of sweeps\n",
    "wandb.agent(sweep_id, train, count=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to-do\n",
    "\n",
    "- [] switch wandb metric from accuracy to val loss. Seems like the config's metric and the one logged using wandb.log() need to be the same.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
