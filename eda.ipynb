{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook fits the baseline model. It predicts on the test data without doing any feature engineering, using the xgboost library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['N_Days', 'Drug', 'Age', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders',\n",
      "       'Edema', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos',\n",
      "       'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin', 'Stage', 'Status',\n",
      "       'source'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv').drop(['id'], axis=1)\n",
    "df_train['source'] = 'simulation'\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "test_ids = df_test.id\n",
    "dt_test = df_test.drop(['id'], axis=1)\n",
    "\n",
    "df_supp = pd.read_csv('data/cirrhosis.csv').drop(['ID'], axis=1)\n",
    "df_supp['source'] = 'original'\n",
    "\n",
    "# merge supplemental data\n",
    "df_train = pd.concat([df_train, df_supp]).reset_index(drop=True)\n",
    "train_target = df_train['Status']\n",
    "\n",
    "# list of discrete columns\n",
    "TARGET = 'Status'\n",
    "CAT_FEATS = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Stage']\n",
    "NUM_FEATS = [x for x in df_train.columns if x not in CAT_FEATS and x != TARGET]\n",
    "NUM_FEATS.remove('source')\n",
    "ORIG_FEATS = df_train.drop(TARGET, axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape: {df_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = df_train.describe(include=\"all\")\n",
    "desc_df = desc_df.T\n",
    "desc_df['unique'] = desc_df['unique'].fillna(df_train.nunique())\n",
    "desc_df['count'] = desc_df['count'].astype('int16')\n",
    "desc_df['missing'] = df_train.shape[0] - desc_df['count']\n",
    "desc_df['dtypes'] = df_train.dtypes\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing values are present but not frequent\n",
    "- only 50 unique values of \"Prothrombin\"\n",
    "\n",
    "dig into missingness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in CAT_FEATS:\n",
    "    print(df_train.loc[:, column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, len(NUM_FEATS) * 2))\n",
    "for i, col in enumerate(NUM_FEATS):\n",
    "    plt.subplot(len(CAT_FEATS) // 2 + 1, 3, i + 1)\n",
    "    sns.histplot(x=col, data=df_train)\n",
    "    plt.title(f\"{col}\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several variables are skewed. Let's see if a logarithmic transformation will help with the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKEWED_FEATS = ['Bilirubin', 'Cholesterol', 'Copper', 'Prothrombin', 'Alk_Phos']\n",
    "df_log_feats = pd.DataFrame()\n",
    "for col in SKEWED_FEATS:\n",
    "    name = f'{col}_log'\n",
    "    df_log_feats[name] = np.log(df_train[col])\n",
    "    \n",
    "for i, col in enumerate(df_log_feats.columns):\n",
    "    plt.subplot(len(df_log_feats.columns) // 2 + 1, 3, i + 1)\n",
    "    sns.histplot(x=col, data=df_log_feats)\n",
    "    plt.title(f\"{col}\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Distribution of the Target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the observations for each category\n",
    "status_counts = df_train[TARGET].value_counts()\n",
    "labels = status_counts.index\n",
    "sizes = status_counts.values\n",
    "\n",
    "# Calculating the percentage of each category\n",
    "percentages = 100.*sizes/sizes.sum()\n",
    "\n",
    "# Creating the pie chart with percentages in the labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(sizes, labels=[f\"{l}, {s:.1f}%\" for l, s in zip(labels, percentages)], startangle=90)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2, 1), labels=labels, title=TARGET)\n",
    "plt.title(f\"Distribution of {TARGET}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are imbalanced and CL is a very small class.\n",
    "\n",
    "Distribution of the features by the target classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, len(CAT_FEATS) * 2))\n",
    "for i, col in enumerate(CAT_FEATS):\n",
    "    plt.subplot(len(CAT_FEATS) // 2 + 1, 3, i + 1)\n",
    "    sns.countplot(x=col, hue=TARGET, data=df_train)\n",
    "    plt.title(f\"{col} vs {TARGET}\")\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"drug\" appears to have no effect on the target\n",
    "- death is most common outcome for males, censored for females\n",
    "- ascites, hepatomegaly, spiders, edema, and stage are associated with death\n",
    "\n",
    "Distribution of the Target by Continuous Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    sns.violinplot(x=TARGET, y=NUM_FEATS[i], data=df_train, ax=ax)\n",
    "    # Set x ticks to be the original labels (inverse transform)\n",
    "    ax.set_title(f\"{NUM_FEATS[i]} vs {TARGET}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are distributed somewhat normally across classes of the target, but there are outliers.\n",
    "\n",
    "Correlation of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "mask = np.triu(np.ones_like(df_train[NUM_FEATS].corr(), dtype=bool))\n",
    "sns.heatmap(df_train[NUM_FEATS].corr(), annot=True, mask=mask, cmap='vlag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bilirubin is correlated with albumin, copper, and n days\n",
    "\n",
    "To investigate correlation by the target classes, use a pairplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot = sns.pairplot(\n",
    "    df_train[NUM_FEATS + [TARGET]].sample(frac=.01), \n",
    "    hue=TARGET, \n",
    "    corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutual Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mi(X, y, discrete):\n",
    "    X = X.copy()\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = discrete\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "X_mi_raw = df_train.dropna().copy()\n",
    "y_mi_raw = X_mi_raw['Status']\n",
    "\n",
    "# encode the categorical features\n",
    "X_mi_cat = X_mi_raw[CAT_FEATS]\n",
    "X_mi_num = np.array(X_mi_raw[NUM_FEATS])\n",
    "oe = OrdinalEncoder()\n",
    "X_mi_cat = oe.fit_transform(X_mi_cat)\n",
    "X_mi = np.concatenate((X_mi_cat, X_mi_num), axis=1)\n",
    "COLUMNS = CAT_FEATS + NUM_FEATS\n",
    "X_mi = pd.DataFrame(X_mi, columns=COLUMNS)\n",
    "\n",
    "# encode the target\n",
    "le = LabelEncoder()\n",
    "y_mi = le.fit_transform(y_mi_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dtype='numeric' is not compatible with arrays of bytes/strings.Convert your data to numeric values explicitly instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# prep data for MI\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mi_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCAT_FEATS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(mi_scores)\n",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m, in \u001b[0;36mmi\u001b[0;34m(X, y, discrete)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# All discrete features should now have integer dtypes\u001b[39;00m\n\u001b[1;32m      6\u001b[0m discrete_features \u001b[38;5;241m=\u001b[39m discrete\n\u001b[0;32m----> 7\u001b[0m mi_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmutual_info_classif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m mi_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(mi_scores, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMI Scores\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      9\u001b[0m mi_scores \u001b[38;5;241m=\u001b[39m mi_scores\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py:468\u001b[0m, in \u001b[0;36mmutual_info_classif\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate mutual information for a discrete target variable.\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03mMutual information (MI) [1]_ between two random variables is a non-negative\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m       of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    467\u001b[0m check_classification_targets(y)\n\u001b[0;32m--> 468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_estimate_mi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py:267\u001b[0m, in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    265\u001b[0m     discrete_mask\u001b[38;5;241m.\u001b[39mfill(discrete_features)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     discrete_features \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m discrete_features\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    269\u001b[0m         discrete_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_features, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:908\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    905\u001b[0m         )\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 908\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m     )\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    916\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: dtype='numeric' is not compatible with arrays of bytes/strings.Convert your data to numeric values explicitly instead."
     ]
    }
   ],
   "source": [
    "# prep data for MI\n",
    "mi_scores = mi(X_mi, y_mi, CAT_FEATS)\n",
    "print(mi_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
